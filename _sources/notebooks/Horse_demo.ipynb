{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649a7dd7",
   "metadata": {},
   "source": [
    "# AmadeusGPT Demo: Horse Gait Analysis\n",
    "\n",
    "- please get an openAI user key: https://platform.openai.com/api-keys.\n",
    "- We suggest to run the demos locally, but it can be viewed on Google Colab. Some interactive features might not be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80877a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --pre amadeusgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd7674",
   "metadata": {},
   "source": [
    "- Let's test that your open AI API Key works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey = \"paste-your-key-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=mykey)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb3204-2a87-4671-8135-2533a7a51771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amadeusgpt import AMADEUS\n",
    "from amadeusgpt.config import Config\n",
    "import amadeusgpt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from amadeusgpt.utils import parse_result\n",
    "from amadeusgpt import create_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646d478",
   "metadata": {},
   "source": [
    "## Please upload the demo video and associated files:\n",
    "- you can grab it from here: https://github.com/AdaptiveMotorControlLab/AmadeusGPT/tree/mwm/docs/examples/Horse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "for filepath, content in uploaded.items():\n",
    "  print(f'User uploaded file \"{filepath}\" with length {len(content)} bytes')\n",
    "\n",
    "video_path = Path(filepath).resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418ecd9",
   "metadata": {},
   "source": [
    "- Set the scene number to visualize your video in a specific frame\n",
    "\n",
    "- ðŸ”¥ Make sure your animal(s) are visible on that frame so gpt-4o can configure AmadeusGPT correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94210808-364c-44a9-a548-b600e75c5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_frame_number = 100\n",
    "amadeus_root = Path(amadeusgpt.__file__).parent.parent\n",
    "config = Config(amadeus_root / \"amadeusgpt/configs/Horse_template.yaml\") #check the path to the config file\n",
    "\n",
    "kwargs = {   \n",
    "    \"video_info.scene_frame_number\" : scene_frame_number,\n",
    "    \"llm_info\": {\n",
    "                \"gpt_model\": \"gpt-4o\",\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "config = create_project(data_folder = \"../examples/Horse\", #check the path to the data folder\n",
    "                        result_folder = \"results\",\n",
    "                        **kwargs\n",
    "                        )\n",
    "\n",
    "amadeus = AMADEUS(config, use_vlm = True)\n",
    "video_file_paths = amadeus.get_video_file_paths()\n",
    "print (video_file_paths)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8af8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_analysis = amadeus.get_behavior_analysis(video_file_path = '../examples/Horse/BrownHorseinShadow.mp4') #check the path to the video file\n",
    "scene_image = behavior_analysis.visual_manager.get_scene_image()\n",
    "plt.imshow(scene_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b3f10-ecba-4ecf-a283-142d2d43ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Plot the gait analysis using Offfrontfoot; Offfrontfetlock; Offknee; Elbow and Shoulder.\"\n",
    "qa_message = amadeus.step(query)\n",
    "qa_message = parse_result(amadeus, qa_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" make an animation of the horse keypoints over time. Overlap the image frame on it. Save the animation on the disk. \"\"\"\n",
    "qa_message = amadeus.step(query)\n",
    "qa_message = parse_result(amadeus, qa_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeusgpt-minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
