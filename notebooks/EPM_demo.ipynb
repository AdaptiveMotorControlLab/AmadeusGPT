{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb3204-2a87-4671-8135-2533a7a51771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If th openai api key is not set already, please set it here.\n",
    "import os\n",
    "if 'OPENAI_API_KEY' not in os.environ:  \n",
    "     os.environ['OPENAI_API_KEY'] = 'your key'\n",
    "import amadeusgpt\n",
    "amadeusgpt.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from amadeusgpt import AMADEUS\n",
    "import amadeusgpt\n",
    "from pathlib import Path\n",
    "import amadeusgpt\n",
    "from amadeusgpt.utils import parse_result\n",
    "from amadeusgpt import create_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c861a70",
   "metadata": {},
   "source": [
    "### Set the scene number to visualize your video in a specific frame\n",
    "### Make sure your animal(s) are visible on that frame so gpt-4o can configure AmadeusGPT correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94210808-364c-44a9-a548-b600e75c5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_frame_number = 400\n",
    "amadeus_root = Path(amadeusgpt.__file__).parent.parent\n",
    "\n",
    "kwargs = {\n",
    "    \"keypoint_info.body_orientation_keypoints.neck\" : \"nose\",\n",
    "    \"keypoint_info.body_orientation_keypoints.tail_base\" : \"tail_base\",\n",
    "    \"keypoint_info.body_orientation_keypoints.animal_center\" : \"neck\",\n",
    "    \"keypoint_info.head_orientation_keypoints.nose\" : \"nose\",\n",
    "    \"keypoint_info.head_orientation_keypoints.neck\" : \"neck\",\n",
    "    \"video_info.scene_frame_number\" : scene_frame_number,\n",
    "}\n",
    "\n",
    "config = create_project(data_folder = \"../examples/EPM\",\n",
    "                        result_folder = \"results\",\n",
    "                        **kwargs\n",
    "                        )\n",
    "amadeus = AMADEUS(config, use_vlm=True)\n",
    "video_file_paths = amadeus.get_video_file_paths()\n",
    "print (video_file_paths)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c27287",
   "metadata": {},
   "source": [
    "### Draw ROIs. Press Esc when you are done drawing each ROI.\n",
    "### After done just run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770c747-c426-4f99-847e-f853c1d32d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_analysis = amadeus.get_behavior_analysis('../examples/EPM/EPM_11.mp4')\n",
    "behavior_analysis.gui_manager.add_roi_from_video_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2257d16",
   "metadata": {},
   "source": [
    "### Get video clips, ethogram and trajectory plots for mouse in the ROI0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bf7af-b75b-4fe5-a422-8fe55aa226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When is the mouse in ROI0\"\n",
    "qa_message = amadeus.step(query)\n",
    "qa_message = parse_result(amadeus, qa_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773a5b2",
   "metadata": {},
   "source": [
    "### You can get a list of binary masks (equivalent to ethogram) for the underlying behavior, if your query is about retriving a described behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496beae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the return masks is of shape (num_of_events, video_length)\n",
    "# where each boolean array of (video_length,) is binary where True indicates whether the behavior is happening at that frame\n",
    "masks = qa_message.get_masks()\n",
    "print (masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b3f10-ecba-4ecf-a283-142d2d43ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Plot the trajectory of the animal using the animal center and color it by time\"\n",
    "qa_message = amadeus.step(query)\n",
    "qa_message = parse_result(amadeus, qa_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83f2ea",
   "metadata": {},
   "source": [
    "### How to retrieve results using the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = amadeus.get_messages()\n",
    "\n",
    "for query, qa_message in messages.items():\n",
    "    print (query)\n",
    "    print (qa_message.get_masks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bb54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amadeusgpt-cpu",
   "language": "python",
   "name": "amadeusgpt-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
